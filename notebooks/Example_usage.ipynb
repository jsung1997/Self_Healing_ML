{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example usage of H_LLM.\n",
    "\n",
    "**Very important**. H-LLM is *not* a product or an algorithm intended to be used outside of the viability setups. As written in the paper, all the studies are *viability* studies that are intended to show the *viability* of self-healing machine learning. We do not recommend using H-LLM as software in any real-life system. \n",
    "\n",
    "This H-LLM class was developed for the sole purpose of showing that the ideas presented in the paper are viable. It is not intended for any other applications. \n",
    "\n",
    "Most importantly, we hope that this work spurs new self-healing research within the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from openai_config import get_openai_config  # Ensure this module contains OpenAI API configuration\n",
    "from openai import AzureOpenAI\n",
    "from HLLM import H_LLM  # Import the H_LLM class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===============================\n",
    "# Setup Configuration\n",
    "# ===============================\n",
    "\n",
    "# Load configuration for Azure OpenAI\n",
    "config = get_openai_config()\n",
    "llm = AzureOpenAI(\n",
    "    api_version=config[\"api_version\"],\n",
    "    azure_endpoint=config[\"api_base\"],\n",
    "    api_key=config[\"api_key\"]\n",
    ")\n",
    "\n",
    "# Initialize the H_LLM instance with a context\n",
    "context = \"The goal is to hypothesize concrete reasons for why the model has underperformed.\"\n",
    "H = H_LLM(config=config, llm=llm, context=context)\n",
    "\n",
    "# ===============================\n",
    "# Data Generation Function\n",
    "# ===============================\n",
    "\n",
    "def generate_diabetes_data(n_samples, seed):\n",
    "    \"\"\"\n",
    "    Generates synthetic diabetes data for binary classification.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    HbA1c = np.random.normal(5.7, 0.5, n_samples)\n",
    "    FastingGlucose = np.random.normal(100, 15, n_samples)\n",
    "    Age = np.random.normal(50, 12, n_samples)\n",
    "    BMI = np.random.normal(25, 4, n_samples)\n",
    "    BloodPressure = np.random.normal(120, 15, n_samples)\n",
    "    Cholesterol = np.random.normal(200, 40, n_samples)\n",
    "    Insulin = np.random.normal(85, 45, n_samples)\n",
    "    PhysicalActivity = np.random.normal(3, 1, n_samples)\n",
    "    \n",
    "    # Combine features into a DataFrame\n",
    "    X = np.vstack((HbA1c, FastingGlucose, Age, BMI, BloodPressure, Cholesterol, Insulin, PhysicalActivity)).T\n",
    "    columns = ['HbA1c', 'FastingGlucose', 'Age', 'BMI', 'BloodPressure', 'Cholesterol', 'Insulin', 'PhysicalActivity']\n",
    "    data = pd.DataFrame(X, columns=columns)\n",
    "    \n",
    "    # Create synthetic binary outcomes\n",
    "    coefficients = np.array([0.3, 0.01, -0.02, 0.04, 0.05, -0.03, -0.01, -0.1])\n",
    "    noise = np.random.normal(0, 0.2, n_samples)\n",
    "    linear_combination = np.dot(X, coefficients) + noise\n",
    "    probabilities = 1 / (1 + np.exp(-linear_combination))\n",
    "    outcomes = (probabilities > 0.5).astype(int)\n",
    "    \n",
    "    return data, outcomes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Basic Hypothesis Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1: Basic Hypothesis Generation ===\n",
      "Accuracy before shift: 0.98\n",
      "Accuracy after shift: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauliusrauba/opt/miniconda3/envs/temporal_degradation/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypotheses generated by H_LLM:\n",
      "Covariate: Age; Hypothesis: The distribution of Age has shifted significantly to the right, which might have affected the model's performance; Evidence: The mean of Age has increased from 49.385257 to 74.600966, and the minimum value has increased from 12.597721 to 19.845456; Strength of belief: Extremely confident.\n",
      "\n",
      "Covariate: BMI; Hypothesis: The distribution of BMI has shifted slightly to the right, which might have affected the model's performance; Evidence: The mean of BMI has increased from 24.924230 to 25.014395, and the minimum value has increased from 10.039597 to 13.511799; Strength of belief: Confident.\n",
      "\n",
      "Covariate: BloodPressure; Hypothesis: The distribution of BloodPressure has shifted slightly to the right, which might have affected the model's performance; Evidence: The mean of BloodPressure has increased from 120.422710 to 121.108888, and the minimum value has decreased from 74.888442 to 71.204486; Strength of belief: Confident.\n",
      "\n",
      "Covariate: HbA1c; Hypothesis: The distribution of HbA1c has shifted slightly to the right, which might have affected the model's performance; Evidence: The mean of HbA1c has increased from 5.677372 to 5.719406, and the minimum value has decreased from 4.176928 to 4.173118; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: FastingGlucose; Hypothesis: The distribution of FastingGlucose has shifted slightly to the right, which might have affected the model's performance; Evidence: The mean of FastingGlucose has increased from 100.204254 to 100.409882, and the minimum value has decreased from 55.080807 to 52.699638; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: Cholesterol; Hypothesis: The distribution of Cholesterol has shifted slightly to the left, which might have affected the model's performance; Evidence: The mean of Cholesterol has decreased from 199.237869 to 197.982496, and the minimum value has decreased from 89.642899 to 69.575396; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: Insulin; Hypothesis: The distribution of Insulin has shifted slightly to the left, which might have affected the model's performance; Evidence: The mean of Insulin has decreased from 85.689157 to 84.271996, and the minimum value has increased from -53.114307 to -46.638727; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: PhysicalActivity; Hypothesis: The distribution of PhysicalActivity has remained relatively stable, which is unlikely to have affected the model's performance; Evidence: The mean of PhysicalActivity has increased slightly from 2.969321 to 2.993207, and the minimum value has decreased from -0.126201 to -0.294858; Strength of belief: Unsure.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Example 1: Basic Hypothesis Generation\n",
    "# ===============================\n",
    "\n",
    "def example_hypothesis_generation():\n",
    "    print(\"=== Example 1: Basic Hypothesis Generation ===\")\n",
    "    \n",
    "    # Generate initial training data and shifted test data\n",
    "    X_before, y_before = generate_diabetes_data(1000, seed=0)\n",
    "    X_after, y_after = generate_diabetes_data(1000, seed=1)\n",
    "    \n",
    "    # Introduce a shift in the 'Age' column to simulate data drift\n",
    "    X_after['Age'] *= 1.5\n",
    "\n",
    "    # Initialize a logistic regression model and fit it on the original data\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_before, y_before)\n",
    "    \n",
    "    # Check model accuracy on shifted data\n",
    "    preds_before = model.predict(X_before)\n",
    "    preds_after = model.predict(X_after)\n",
    "    acc_before = accuracy_score(y_before, preds_before)\n",
    "    acc_after = accuracy_score(y_after, preds_after)\n",
    "    \n",
    "    print(f\"Accuracy before shift: {acc_before:.2f}\")\n",
    "    print(f\"Accuracy after shift: {acc_after:.2f}\")\n",
    "    \n",
    "    # Use H_LLM to hypothesize issues with model performance\n",
    "    hypotheses = H.hypothesize_issues_with_performance(X_before, X_after, y_before, y_after, model, context)\n",
    "    print(\"Hypotheses generated by H_LLM:\")\n",
    "    print(hypotheses)\n",
    "    \n",
    "example_hypothesis_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Covariate Combination Hypotheses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example 2: Covariate Combination Hypotheses ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauliusrauba/opt/miniconda3/envs/temporal_degradation/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariate combination hypotheses:\n",
      "[[5. The mean of BMI has increased significantly after the shift, which might have affected the model's performance.],\n",
      "[1. The mean of FastingGlucose has increased significantly after the shift, which might have affected the model's performance.],\n",
      "[4. The maximum value of FastingGlucose has increased significantly, which might have affected the model's performance.],\n",
      "[8. The maximum value of BMI has increased significantly, which might have affected the model's performance.],\n",
      "[7. The minimum value of BMI has increased significantly, which might have affected the model's performance.],\n",
      "[3. The minimum value of FastingGlucose has increased, which might have affected the model's performance.],\n",
      "[2. The standard deviation of FastingGlucose has also increased, indicating a wider spread of data which might have affected the model's performance.],\n",
      "[6. The standard deviation of BMI has decreased, indicating a narrower spread of data which might have affected the model's performance.],\n",
      "[13. The mean of Insulin has increased slightly after the shift, which might have affected the model's performance.],\n",
      "[16. The maximum value of Insulin has increased slightly, which might have affected the model's performance.],\n",
      "[9. The mean of Age has decreased slightly after the shift, which might have affected the model's performance.],\n",
      "[12. The maximum value of Age has decreased significantly, which might have affected the model's performance.],\n",
      "[11. The minimum value of Age has increased slightly, which might have affected the model's performance.],\n",
      "[10. The standard deviation of Age has decreased, indicating a narrower spread of data which might have affected the model's performance.],\n",
      "[14. The standard deviation of Insulin has decreased, indicating a narrower spread of data which might have affected the model's performance.],\n",
      "[15. The minimum value of Insulin has decreased slightly, which might have affected the model's performance.],\n",
      "[17. The mean of PhysicalActivity has decreased slightly after the shift, which might have affected the model's performance.],\n",
      "[20. The maximum value of PhysicalActivity has decreased slightly, which might have affected the model's performance.],\n",
      "[19. The minimum value of PhysicalActivity has increased significantly, which might have affected the model's performance.],\n",
      "[18. The standard deviation of PhysicalActivity has decreased, indicating a narrower spread of data which might have affected the model's performance.]]\n",
      "\n",
      "Suggested queries for data filtering:\n",
      "OUTPUT: \n",
      "Query 1: df['BMI'] > df['BMI'].mean() + df['BMI'].std();\n",
      "Query 2: df['FastingGlucose'] > df['FastingGlucose'].mean() + df['FastingGlucose'].std();\n",
      "Query 3: df['FastingGlucose'] > df['FastingGlucose'].max() - df['FastingGlucose'].std();\n",
      "Query 4: df['BMI'] > df['BMI'].max() - df['BMI'].std();\n",
      "Query 5: df['BMI'] < df['BMI'].mean() - df['BMI'].std();\n",
      "Query 6: df['FastingGlucose'] < df['FastingGlucose'].mean() - df['FastingGlucose'].std();\n",
      "Query 7: df['FastingGlucose'] > df['FastingGlucose'].std();\n",
      "Query 8: df['BMI'] < df['BMI'].std();\n",
      "Query 9: df['Insulin'] > df['Insulin'].mean() + df['Insulin'].std();\n",
      "Query 10: df['Insulin'] > df['Insulin'].max() - df['Insulin'].std();\n",
      "Query 11: df['Age'] < df['Age'].mean() - df['Age'].std();\n",
      "Query 12: df['Age'] < df['Age'].max() - df['Age'].std();\n",
      "Query 13: df['Age'] > df['Age'].mean() + df['Age'].std();\n",
      "Query 14: df['Age'] < df['Age'].std();\n",
      "Query 15: df['Insulin'] < df['Insulin'].std();\n",
      "Query 16: df['Insulin'] < df['Insulin'].mean() - df['Insulin'].std();\n",
      "Query 17: df['PhysicalActivity'] < df['PhysicalActivity'].mean() - df['PhysicalActivity'].std();\n",
      "Query 18: df['PhysicalActivity'] < df['PhysicalActivity'].max() - df['PhysicalActivity'].std();\n",
      "Query 19: df['PhysicalActivity'] > df['PhysicalActivity'].mean() + df['PhysicalActivity'].std();\n",
      "Query 20: df['PhysicalActivity'] < df['PhysicalActivity'].std().\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Example 2: Covariate Combination Hypotheses\n",
    "# ===============================\n",
    "\n",
    "def example_covariate_combinations():\n",
    "    print(\"\\n=== Example 2: Covariate Combination Hypotheses ===\")\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    # Generate initial training data and shifted test data\n",
    "    X_before, y_before = generate_diabetes_data(1000, seed=42)\n",
    "    X_after, y_after = generate_diabetes_data(1000, seed=24)\n",
    "\n",
    "    model.fit(X_before, y_before)\n",
    "\n",
    "    \n",
    "    # Introduce shifts in multiple covariates\n",
    "    X_after['FastingGlucose'] *= 1.2\n",
    "    X_after['BMI'] += 5\n",
    "    \n",
    "    # Use H_LLM to generate hypotheses for covariate combinations\n",
    "    hypotheses, queries = H.hypothesize_issues_with_performance_covariate_combinations(X_before, X_after, y_before, y_after, model, context)\n",
    "    \n",
    "    print(\"Covariate combination hypotheses:\")\n",
    "    print(hypotheses)\n",
    "    print(\"\\nSuggested queries for data filtering:\")\n",
    "    print(queries)\n",
    "\n",
    "example_covariate_combinations()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Adaptive Model Retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Example 1: Basic Hypothesis Generation ===\n",
      "Accuracy before shift: 0.98\n",
      "Accuracy after shift: 0.89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauliusrauba/opt/miniconda3/envs/temporal_degradation/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hypotheses generated by H_LLM:\n",
      "Covariate: Age; Hypothesis: The significant shift in the Age covariate has likely caused the model to underperform; Evidence: The mean of Age has significantly increased after the shift. Also, the model's accuracy has decreased in most of the ranges of Age after the shift; Strength of belief: Extremely confident.\n",
      "\n",
      "Covariate: HbA1c; Hypothesis: The model's performance has degraded due to the shift in the HbA1c covariate; Evidence: The mean of HbA1c has slightly increased after the shift. Also, the model's accuracy has decreased in most of the ranges of HbA1c after the shift; Strength of belief: Confident.\n",
      "\n",
      "Covariate: FastingGlucose; Hypothesis: The shift in the FastingGlucose covariate might have contributed to the model's underperformance; Evidence: The mean of FastingGlucose has slightly increased after the shift. However, the model's accuracy has not significantly changed in most of the ranges of FastingGlucose after the shift; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: BMI; Hypothesis: The shift in the BMI covariate might have contributed to the model's underperformance; Evidence: The mean of BMI has slightly increased after the shift. However, the model's accuracy has not significantly changed in most of the ranges of BMI after the shift; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: BloodPressure; Hypothesis: The shift in the BloodPressure covariate might have contributed to the model's underperformance; Evidence: The mean of BloodPressure has slightly increased after the shift. However, the model's accuracy has not significantly changed in most of the ranges of BloodPressure after the shift; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: Cholesterol; Hypothesis: The shift in the Cholesterol covariate might have contributed to the model's underperformance; Evidence: The mean of Cholesterol has slightly decreased after the shift. However, the model's accuracy has not significantly changed in most of the ranges of Cholesterol after the shift; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: Insulin; Hypothesis: The shift in the Insulin covariate might have contributed to the model's underperformance; Evidence: The mean of Insulin has slightly decreased after the shift. However, the model's accuracy has not significantly changed in most of the ranges of Insulin after the shift; Strength of belief: Somewhat confident.\n",
      "\n",
      "Covariate: PhysicalActivity; Hypothesis: The shift in the PhysicalActivity covariate might have contributed to the model's underperformance; Evidence: The mean of PhysicalActivity has slightly increased after the shift. However, the model's accuracy has not significantly changed in most of the ranges of PhysicalActivity after the shift; Strength of belief: Somewhat confident.\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Example 3: Adaptive Model Retraining\n",
    "# ===============================\n",
    "\n",
    "def example_adaptive_retraining():\n",
    "    print(\"\\n=== Example 3: Adaptive Model Retraining ===\")\n",
    "    \n",
    "    # Generate initial training data and shifted test data\n",
    "    X_before, y_before = generate_diabetes_data(1000, seed=123)\n",
    "    X_after, y_after = generate_diabetes_data(1000, seed=321)\n",
    "    \n",
    "    # Simulate a shift in 'BloodPressure'\n",
    "    X_after['BloodPressure'] *= 1.3\n",
    "    \n",
    "    # Split X_after into a backtesting set\n",
    "    X_after, X_backtest, y_after, y_backtest = train_test_split(X_after, y_after, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Initialize a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_before, y_before)\n",
    "    \n",
    "    # Use H_LLM to fit the model adaptively based on covariate shifts\n",
    "    adapted_model = H.fit_model(model, X_before, X_after, y_after, X_backtest, y_backtest)\n",
    "    \n",
    "    # Evaluate the adapted model\n",
    "    preds = adapted_model.predict(X_backtest)\n",
    "    acc = accuracy_score(y_backtest, preds)\n",
    "    print(f\"Accuracy of the adapted model: {acc:.2f}\")\n",
    "\n",
    "\n",
    "# Run examples\n",
    "example_hypothesis_generation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 4: Suggesting Data Removal Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Example 2: Suggesting Data Removal Queries ===\n",
      "Suggested queries to remove problematic data:\n",
      "1. Subgroup: Age > 90; Reason: The maximum age has increased significantly, which could be skewing the data.\n",
      "2. Subgroup: Blood Pressure > 160; Reason: The mean blood pressure has increased significantly, removing higher values could normalize the data.\n",
      "3. Subgroup: Fasting Glucose < 60; Reason: The mean fasting glucose has decreased, removing lower values could normalize the data.\n",
      "4. Subgroup: Insulin < 0; Reason: The minimum value for insulin is negative, which is not possible, suggesting errors in the data.\n",
      "5. Subgroup: Physical Activity < 1; Reason: The mean physical activity has decreased and the minimum value is negative, suggesting errors in the data.\n",
      "6. Subgroup: BMI > 35; Reason: The mean BMI has increased slightly, removing higher values could normalize the data.\n",
      "7. Subgroup: Cholesterol > 300; Reason: The mean cholesterol has increased slightly, removing higher values could normalize the data.\n",
      "8. Subgroup: HbA1c < 5; Reason: The mean HbA1c has decreased slightly, removing lower values could normalize the data.\n",
      "9. Subgroup: Age > 90 and Blood Pressure > 160; Reason: Both age and blood pressure have increased significantly, removing the intersection of these two subgroups could normalize the data.\n",
      "10. Subgroup: Insulin < 0 and Physical Activity < 1; Reason: Both insulin and physical activity have negative minimum values, suggesting errors in the data. Removing the intersection of these two subgroups could improve the data quality.\n",
      "\n",
      "Formatted queries for pandas filtering:\n",
      "['Age > 90', 'BloodPressure > 160', 'FastingGlucose < 60', 'Insulin < 0', 'PhysicalActivity < 1', 'BMI > 35', 'Cholesterol > 300', 'HbA1c < 5', 'Age > 90 & BloodPressure > 160', 'Insulin < 0 & PhysicalActivity < 1']\n"
     ]
    }
   ],
   "source": [
    "def generate_synthetic_data(n_samples, seed):\n",
    "    \"\"\"\n",
    "    Generates synthetic dataset with numerical features.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    HbA1c = np.random.normal(5.7, 0.5, n_samples)\n",
    "    FastingGlucose = np.random.normal(100, 15, n_samples)\n",
    "    Age = np.random.normal(50, 12, n_samples)\n",
    "    BMI = np.random.normal(25, 4, n_samples)\n",
    "    BloodPressure = np.random.normal(120, 15, n_samples)\n",
    "    Cholesterol = np.random.normal(200, 40, n_samples)\n",
    "    Insulin = np.random.normal(85, 45, n_samples)\n",
    "    PhysicalActivity = np.random.normal(3, 1, n_samples)\n",
    "    \n",
    "    # Combine features into a DataFrame\n",
    "    columns = ['HbA1c', 'FastingGlucose', 'Age', 'BMI', 'BloodPressure', 'Cholesterol', 'Insulin', 'PhysicalActivity']\n",
    "    data = pd.DataFrame(np.vstack((HbA1c, FastingGlucose, Age, BMI, BloodPressure, Cholesterol, Insulin, PhysicalActivity)).T, columns=columns)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# ===============================\n",
    "# Example 4: Suggesting Data Removal Queries\n",
    "# ===============================\n",
    "\n",
    "def example_suggest_data_removal_queries():\n",
    "    print(\"\\n=== Example 2: Suggesting Data Removal Queries ===\")\n",
    "\n",
    "    # Generate initial dataset and shifted dataset\n",
    "    X_before = generate_synthetic_data(1000, seed=42)\n",
    "    X_after = generate_synthetic_data(1000, seed=24)\n",
    "\n",
    "    # Introduce shifts in multiple covariates\n",
    "    X_after['Age'] *= 1.5\n",
    "    X_after['BloodPressure'] += 20\n",
    "\n",
    "    # Use H_LLM to hypothesize issues and suggest data removal queries\n",
    "    issues = H.hypothesize_issues(X_before, X_after, context)\n",
    "    removal_queries = H.suggest_solutions_remove_data(issues, X_before, X_after)\n",
    "\n",
    "    print(\"Suggested queries to remove problematic data:\")\n",
    "    print(removal_queries)\n",
    "\n",
    "    # Convert the queries into a list format for use with pandas filtering\n",
    "    formatted_queries = H.convert_to_list_of_queries(removal_queries, X_before)\n",
    "    print(\"\\nFormatted queries for pandas filtering:\")\n",
    "    print(formatted_queries)\n",
    "\n",
    "example_suggest_data_removal_queries()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temporal_degradation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
